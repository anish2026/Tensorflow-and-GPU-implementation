{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06df82c4-b9af-40d5-888e-ec839eec4464",
   "metadata": {},
   "source": [
    "Â© Anish Anand \n",
    "# In this lab , we are going to work on CIFAR10 small images classification dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ce9d49-ca09-46f6-9367-1aa40de9b48e",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    " Link to dataset to read more : https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8ad0d0-882b-4b15-8881-140a4a17f95a",
   "metadata": {},
   "source": [
    "## Important feature of the dataset \n",
    "\n",
    "1. It has 10 classes  [airplane\n",
    ",automobile\n",
    ",bird\n",
    ",cat\n",
    ",deer\n",
    ",dog\n",
    ",frog\n",
    ",horse\n",
    ",ship\n",
    ",truck]\n",
    "\n",
    "2. consists of 60000 32x32 colour images\n",
    "\n",
    "3. No. of training images : 50000\n",
    "\n",
    "4. No. of testing images 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60307409-ca83-4cd9-a408-0d18f27f14e4",
   "metadata": {},
   "source": [
    "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56faf865-82d3-43ae-b1d7-68f5c2e03816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97d61d5-a571-4098-bc6c-6e782e36fcca",
   "metadata": {},
   "source": [
    "Now we are loading the dataset by just referring the load data function. Since the dataset belongs to Keras so we have already a function to load this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03c916ab-76d7-4658-93d7-9e2968b4f463",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01ffb634-061c-4a81-a86c-e81d8a851080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "762ae58b-c1c9-4834-a895-0e28c8d834a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ba4ff58-07bc-4647-867b-a3b88eff5856",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5556de8-6a0e-4606-be4a-8c7612c6fe9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0d61722-56d5-44e6-ab80-1961fdcea089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8cf5e46b-eeca-49ae-9a1f-61dd92956b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b89a422d-420a-43f6-b225-62206909f3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bef33c-5326-45bc-9d5b-6313bec863cf",
   "metadata": {},
   "source": [
    "So till now we can conclude the following points:\n",
    "\n",
    "1. x_train and x_test are 50000 and 10000 images respectively whose sizes are 32 X 32 and consist the third dimension as RGB therefore 3.\n",
    "\n",
    "2. y_train and y_test are 50000 and 10000 images respectively which has information about the class in which they belong.\n",
    "\n",
    "3. We have 10 classes and we are training at least 10000 images to each class and nthen predicting it right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235730a7-2aa7-4133-9d7b-b1b845239110",
   "metadata": {},
   "source": [
    "## 1.Preprocessing the images\n",
    "\n",
    "We are scaling images so that there must not be any ambiguity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86dd5678-ae68-4df0-a6c0-d286cfa2ec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = x_train/255\n",
    "X_test_scaled = x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8768c569-91d1-4a16-b9cc-3199b6c5c45a",
   "metadata": {},
   "source": [
    "#### Ques : Why we divide with 255?\n",
    "\n",
    "#### Ans: Because each and every images present in training and testing dataset has range from 0 to 255 because RGB ranges the same. Dividing with the highest value we are actually normalising the matrix values so the model can perform well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d30a36f-d236-4b26-baed-77ea7c484e26",
   "metadata": {},
   "source": [
    "## 2.Performing One hot encoding (part of preprocessing if images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dc50c6-a299-4f86-9407-d6cfc26e9d11",
   "metadata": {},
   "source": [
    "One hot encoding is a process by which categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction. For example if we have 3 classes and we have one image which lies in the 2nd class then we can represent this information as [0,1,0]. This is what we have done One Hot Encoding.\n",
    "\n",
    "SO here we have 10 classes which means that when any image given belongs to 2nd class then we can represent this as [0,1,0,0,0,0,0,0,0,0].\n",
    "\n",
    "Luckily we dont not need to create list full of zero everytime and adjust values accordingly , istead of that we can do this by using an API which keras has keras.utils.to_categorical()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ea7bf8c-62d9-4f9b-b927-b5fb7283c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing one hot encoding \n",
    "\n",
    "y_train_categorical = keras.utils.to_categorical(\n",
    "    y_train, num_classes=10, dtype='float32'\n",
    ")\n",
    "y_test_categorical = keras.utils.to_categorical(\n",
    "    y_test, num_classes=10, dtype='float32'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99944f0f-80a4-40ca-8524-6128c91e7e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       [4],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "770868d5-1749-4901-ac27-d22157e9a7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_categorical[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2ba9d1-0c75-4dff-9855-76ec3e07daa3",
   "metadata": {},
   "source": [
    "Outpit 19 and output 20 just telling us the difference between image classes after one hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6a6293-94e2-4c05-9449-deeee0e4a222",
   "metadata": {},
   "source": [
    "## 3. Model Building now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6dca139-1d73-4523-bf32-e9ef99ba180d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 13s 8ms/step - loss: 1.8113 - accuracy: 0.3535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26d6c78ef10>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(32,32,3)),\n",
    "    keras.layers.Dense(3000,activation='relu'),\n",
    "    keras.layers.Dense(1000,activation='relu'),\n",
    "    keras.layers.Dense(10,activation='sigmoid')\n",
    "])\n",
    "\n",
    "#we have built our neural network so far\n",
    "#we have built just Artificial Neural Network \n",
    "\n",
    "#compiling the model\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train_categorical, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17ea567-f0fe-4382-b9a8-fbedd20043bc",
   "metadata": {},
   "source": [
    "## 4. Making prediction now\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1d4c5b43-09ef-4731-a530-87dedd982320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37141418, 0.52542984, 0.7199892 , 0.7889977 , 0.3919865 ,\n",
       "       0.6188356 , 0.6664617 , 0.14196117, 0.5393762 , 0.17657457],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets predict the first image from test dataset\n",
    "\n",
    "model.predict(X_test_scaled)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e7d042db-3fbf-4288-a2ae-4143bbaf31b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in above it is probability of each class and we actually use np.argmax function to filter the maximum probability\n",
    "\n",
    "np.argmax(model.predict(X_test_scaled)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "25ebacc0-307a-4c07-b7cb-b6b6c91d6772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting class 3, lets see what is in class[3]\n",
    "\n",
    "classes[np.argmax(model.predict(X_test_scaled)[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b698db7c-4695-4693-ac94-5ff3b086d2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3], dtype=uint8)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now lets check what actually the first image is\n",
    "\n",
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f303aefe-7494-498e-adbf-93605910b1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[y_test[0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16eaa1f-1f5c-4c1d-bcc1-cc3390099441",
   "metadata": {},
   "source": [
    "So far we saw that we have built our model and it predicting correctly.\n",
    "\n",
    "### Now our task would be to compare the performance of GPU and CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a9bcd4b1-cb48-459f-a6a7-392fe5463b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first of all I am making a copy of my model and will call it when needed \n",
    "def get_model():\n",
    "    model = keras.Sequential([\n",
    "            keras.layers.Flatten(input_shape=(32,32,3)),\n",
    "            keras.layers.Dense(3000, activation='relu'),\n",
    "            keras.layers.Dense(1000, activation='relu'),\n",
    "            keras.layers.Dense(10, activation='sigmoid')    \n",
    "        ])\n",
    "\n",
    "    model.compile(optimizer='SGD',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d883378-f648-4ee8-813b-b2fd5bb8dd9e",
   "metadata": {},
   "source": [
    "## Measuring training time on CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b0b7e9b0-51d1-4429-bdac-5f24f6d3b059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 167s 106ms/step - loss: 1.8135 - accuracy: 0.3534\n",
      "2min 57s Â± 0 ns per loop (mean Â± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1 #measures time taken by a cell to run\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    cpu_model = get_model()\n",
    "    cpu_model.fit(X_train_scaled, y_train_categorical, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be4208e-fb79-4c7b-9907-48ed0ab85254",
   "metadata": {},
   "source": [
    "## Measuring training time on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f2de3fe8-7a3b-415e-9bb2-99a522dde003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 13s 8ms/step - loss: 1.8064 - accuracy: 0.3542\n",
      "15.2 s Â± 0 ns per loop (mean Â± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "with tf.device('/GPU:0'):\n",
    "    cpu_model = get_model()\n",
    "    cpu_model.fit(X_train_scaled, y_train_categorical, epochs=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d19055-3518-4b24-acf5-c5f30df0911d",
   "metadata": {},
   "source": [
    "Just for 1 epoch we have seen the GPU is almost 7 times faster than CPU\n",
    "\n",
    "## Repeating the same process for 10 epochs\n",
    "\n",
    "### CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4c85c99d-2026-42b0-a123-87c62a8b64f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 168s 107ms/step - loss: 1.8140 - accuracy: 0.3533\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 164s 105ms/step - loss: 1.6253 - accuracy: 0.4259\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 171s 110ms/step - loss: 1.5443 - accuracy: 0.4579\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 181s 116ms/step - loss: 1.4813 - accuracy: 0.4772\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 144s 92ms/step - loss: 1.4341 - accuracy: 0.4940\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 139s 89ms/step - loss: 1.3901 - accuracy: 0.5123\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 137s 87ms/step - loss: 1.3525 - accuracy: 0.5243\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 136s 87ms/step - loss: 1.3154 - accuracy: 0.5400\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 136s 87ms/step - loss: 1.2853 - accuracy: 0.5484\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 139s 89ms/step - loss: 1.2547 - accuracy: 0.5587\n",
      "25min 17s Â± 0 ns per loop (mean Â± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1 #measures time taken by a cell to run\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    cpu_model = get_model()\n",
    "    cpu_model.fit(X_train_scaled, y_train_categorical, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8443ba15-b5b6-43b6-adf1-e6c79434a547",
   "metadata": {},
   "source": [
    "### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "317a54de-a2c3-41eb-98db-f322a0c5d43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 1.8144 - accuracy: 0.3549\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.6237 - accuracy: 0.4260\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.5404 - accuracy: 0.4551\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.4815 - accuracy: 0.4777\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.4308 - accuracy: 0.4971\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.3876 - accuracy: 0.5120\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.3512 - accuracy: 0.5257\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.3162 - accuracy: 0.5397\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.2826 - accuracy: 0.5482\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.2515 - accuracy: 0.5595\n",
      "2min 7s Â± 0 ns per loop (mean Â± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "with tf.device('/GPU:0'):\n",
    "    cpu_model = get_model()\n",
    "    cpu_model.fit(X_train_scaled, y_train_categorical, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35665365-0673-4b09-9077-a552c13a1c3e",
   "metadata": {},
   "source": [
    "## Result : GPU is almost 12 times faster than CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6260a6-2541-44a0-a43f-d18c6bb06e47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
